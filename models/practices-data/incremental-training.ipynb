{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import required libraries and components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Read the data set that you generated in the previous notebook.\n",
    "For convenience, save the train and test subsets in CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Generate train and test splits\n",
    "train_data, test_data = train_test_split(\n",
    "    data,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "train_data.to_csv(\"train_subset.csv\", index=False)\n",
    "test_data.to_csv(\"test_subset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define the same data engineering function as in the preceding notebook to apply the same transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    variations = [df]\n",
    "    for i in range(1):\n",
    "        variations.append(df.copy() * i)\n",
    "\n",
    "    df_extended = pd.concat(variations, axis=1)\n",
    "\n",
    "    return df_extended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the model by streaming the data from the file in chunks and preprocessing each chunk at once.\n",
    "By doing so, only some of the data needs to fit into memory at the same time.\n",
    "\n",
    "> NOTE You must use classifiers that work well with piecemeal, or \"out-of-core\", training.\n",
    "The `GaussianNB` classifier, or Gaussian naive-Bayes, is one such classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch 1 done\n",
      "Training batch 2 done\n",
      "Training batch 3 done\n",
      "Training batch 4 done\n",
      "Training batch 5 done\n",
      "Training batch 6 done\n",
      "Training batch 7 done\n",
      "Training batch 8 done\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "batches = 0\n",
    "for minibatch in pd.read_csv(\"train_subset.csv\", chunksize=1000):\n",
    "    X = minibatch.drop('target', axis=1)\n",
    "    y = minibatch['target']\n",
    "    X_processed = preprocess(X)\n",
    "    model.partial_fit(X_processed, y, classes=y.unique())\n",
    "\n",
    "    batches += 1\n",
    "    print(f\"Training batch {batches} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1003\n",
      "           1       0.81      0.63      0.71       997\n",
      "\n",
      "    accuracy                           0.74      2000\n",
      "   macro avg       0.76      0.74      0.74      2000\n",
      "weighted avg       0.76      0.74      0.74      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test_subset.csv\")\n",
    "X_test = test_data.drop('target', axis=1)\n",
    "y_test = test_data['target']\n",
    "\n",
    "\n",
    "y_predicted = model.predict(preprocess(X_test))\n",
    "\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
