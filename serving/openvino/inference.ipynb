{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Make Inference Requests to Deployed Model\n",
    "\n",
    "This notebook demonstrates how to make authenticated inference requests to a model deployed with OpenVINO Model Server using the KServe V2 API.\n",
    "\n",
    "You will:\n",
    "1. Retrieve the model server route and authentication token\n",
    "2. Load and preprocess a sample image\n",
    "3. Send an inference request using the KServe V2 protocol\n",
    "4. Process and display the prediction results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Retrieve Model Server Route\n",
    "\n",
    "Get the external route for the deployed model server using the OpenShift CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "model_route = subprocess.check_output([\n",
    "    \"oc\", \"get\", \"route\", \"image-classifier-server\",\n",
    "    \"-n\", \"ai0017l-wb\",\n",
    "    \"-o\", \"jsonpath={.spec.host}\"\n",
    "]).decode().strip()\n",
    "\n",
    "model_url = f\"https://{model_route}/v2/models/image-classifier/infer\"\n",
    "print(f\"Model URL: {model_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Retrieve Authentication Token\n",
    "\n",
    "Get a service account token for authenticating requests to the model server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = subprocess.check_output([\"oc\", \"whoami\", \"-t\"]).decode().strip()\n",
    "print(f\"Token retrieved: {token[:20]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. Import Required Libraries\n",
    "\n",
    "Import libraries for image processing, HTTP requests, and numerical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# Disable SSL warnings for self-signed certificates in lab environments\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08g9ymw4zye6",
   "source": "## 4. Load ImageNet Class Labels\n\nLoad the ImageNet class labels for mapping prediction indices to human-readable class names.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "fg05fjfo1gp",
   "source": "# Download ImageNet class labels\nimport urllib.request\n\nlabels_url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\nlabels_path = Path(\"data/imagenet_labels.json\")\n\n# Create data directory if it doesn't exist\nlabels_path.parent.mkdir(parents=True, exist_ok=True)\n\n# Download labels if not already present\nif not labels_path.exists():\n    print(f\"Downloading ImageNet labels from {labels_url}...\")\n    urllib.request.urlretrieve(labels_url, labels_path)\n    print(\"✓ Labels downloaded successfully\")\nelse:\n    print(\"✓ ImageNet labels already exist\")\n\n# Load labels\nwith open(labels_path, 'r') as f:\n    imagenet_labels = json.load(f)\n\nprint(f\"Loaded {len(imagenet_labels)} ImageNet class labels\")\nprint(f\"Example labels: {imagenet_labels[:5]}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": "## 5. Load and Preprocess Sample Image\n\nLoad a sample image and preprocess it to match the model's expected input format.\n\n**Preprocessing Steps:**\n1. Resize image to 224x224 pixels\n2. Convert to RGB format\n3. Normalize pixel values using ImageNet statistics\n4. Transpose to channel-first format (C, H, W)\n5. Add batch dimension"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "image_path = Path(\"data/sample_image.jpg\")\n",
    "if not image_path.exists():\n",
    "    raise FileNotFoundError(f\"Sample image not found: {image_path}\")\n",
    "\n",
    "image = Image.open(image_path)\n",
    "print(f\"Original image size: {image.size}\")\n",
    "\n",
    "# Resize to 224x224\n",
    "image = image.resize((224, 224))\n",
    "image = image.convert('RGB')\n",
    "\n",
    "# Convert to numpy array and normalize\n",
    "image_array = np.array(image).astype(np.float32) / 255.0\n",
    "\n",
    "# Apply ImageNet normalization\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "image_array = (image_array - mean) / std\n",
    "\n",
    "# Transpose to channel-first format (C, H, W)\n",
    "image_array = np.transpose(image_array, (2, 0, 1))\n",
    "\n",
    "# Add batch dimension (N, C, H, W)\n",
    "image_array = np.expand_dims(image_array, axis=0)\n",
    "\n",
    "print(f\"Preprocessed image shape: {image_array.shape}\")\n",
    "print(f\"Image data type: {image_array.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": "## 6. Construct KServe V2 Inference Request\n\nBuild the inference request payload following the KServe V2 protocol specification.\n\n**KServe V2 Request Format:**\n- `inputs`: Array of input tensors with name, shape, datatype, and data\n- Input tensor name must match the model's expected input name (\"input\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct KServe V2 inference request payload\n",
    "inference_request = {\n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"input\",\n",
    "            \"shape\": list(image_array.shape),\n",
    "            \"datatype\": \"FP32\",\n",
    "            \"data\": image_array.flatten().tolist()\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Inference request payload constructed\")\n",
    "print(f\"Input shape: {inference_request['inputs'][0]['shape']}\")\n",
    "print(f\"Input datatype: {inference_request['inputs'][0]['datatype']}\")\n",
    "print(f\"Number of values: {len(inference_request['inputs'][0]['data'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": "## 7. Send Inference Request\n\nSend the inference request to the model server with authentication headers."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up request headers with authentication\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Send POST request to model server\n",
    "print(f\"Sending inference request to {model_url}...\")\n",
    "response = requests.post(\n",
    "    model_url,\n",
    "    headers=headers,\n",
    "    json=inference_request,\n",
    "    verify=False  # Disable SSL verification for self-signed certificates\n",
    ")\n",
    "\n",
    "# Check response status\n",
    "if response.status_code == 200:\n",
    "    print(\"✓ Inference request successful!\")\n",
    "else:\n",
    "    print(f\"✗ Inference request failed with status code: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")\n",
    "    raise Exception(\"Inference request failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": "## 8. Process Inference Results\n\nParse the response and extract prediction probabilities for each ImageNet class."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse JSON response\n",
    "result = response.json()\n",
    "\n",
    "# Extract prediction data from KServe V2 response\n",
    "predictions = np.array(result['outputs'][0]['data'])\n",
    "\n",
    "# Reshape to match output shape if needed\n",
    "output_shape = result['outputs'][0]['shape']\n",
    "predictions = predictions.reshape(output_shape)\n",
    "\n",
    "print(f\"Output shape: {predictions.shape}\")\n",
    "print(f\"Predictions (first 10): {predictions[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": "## 9. Display Top Predictions\n\nFind the top predicted classes and display their confidence scores with human-readable labels."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": "# Get top 5 predictions\ntop_k = 5\ntop_indices = np.argsort(predictions[0])[-top_k:][::-1]\ntop_probabilities = predictions[0][top_indices]\n\n# Get human-readable labels for top predictions\ntop_labels = [imagenet_labels[idx] for idx in top_indices]\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Inference request successful!\")\nprint(f\"Predictions: [{', '.join([f'{p:.3f}' for p in predictions[0][:10]])}, ...]\")\nprint(f\"Top prediction: Class {top_indices[0]} (confidence: {top_probabilities[0]*100:.1f}%)\")\nprint(\"=\"*50)\n\nprint(f\"\\nTop {top_k} predictions:\")\nfor i, (idx, label, prob) in enumerate(zip(top_indices, top_labels, top_probabilities), 1):\n    print(f\"{i}. {label} (class {idx}): {prob*100:.1f}% confidence\")"
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": "## Summary\n\nYou have successfully:\n1. Retrieved the model server route using OpenShift CLI\n2. Obtained an authentication token for secure access\n3. Downloaded ImageNet class labels for human-readable predictions\n4. Loaded and preprocessed an image using ImageNet normalization\n5. Constructed a KServe V2 inference request payload\n6. Sent an authenticated inference request to the deployed model\n7. Processed and displayed the prediction results with class names\n\nThis demonstrates the complete workflow for making inference requests to models deployed with OpenVINO Model Server in Red Hat OpenShift AI.\n\nThe predictions show both class indices (0-999) and human-readable labels from the ImageNet dataset, making it easy to interpret the model's predictions."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}